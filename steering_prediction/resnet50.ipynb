{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance, ImageFile\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def processor(root_data_dir, save_dir):\n",
    "    \n",
    "    for file in root_data_dir.iterdir():\n",
    "        if file.suffix == \".jpg\":\n",
    "            img = Image.open(file) # print(img.size)\n",
    "            # BLUR\n",
    "            img = img.filter(ImageFilter.BLUR)\n",
    "            # DARKEN IMG\n",
    "            enhancer = ImageEnhance.Brightness(img)\n",
    "            img = enhancer.enhance(0.5)\n",
    "            # CROP\n",
    "            width, height = img.size\n",
    "            img = img.crop((0, 140, width, height)) # try 120-150\n",
    "            \n",
    "            img.save(save_dir/file.name)\n",
    "            print(\"processed : \", save_dir/file.name)\n",
    "    \n",
    "        if str(file.stem)==\"data\":\n",
    "                    shutil.copy(str(file), str(save_dir/file.name) )\n",
    "        \n",
    "    \n",
    "\n",
    "def preprocess(root_data_dir, save_dir, delete_existing = False):\n",
    "    start = time.time()\n",
    "    if save_dir.exists():\n",
    "        if delete_existing:\n",
    "            print(\"Deleting existing preprocessed dir and \")\n",
    "            time.sleep(1)\n",
    "            shutil.rmtree(save_dir, ignore_errors=True)\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            processor(root_data_dir, save_dir)\n",
    "            \n",
    "        else:\n",
    "            print(\"A preprocessed dir exists, Data might be preprocessed\")\n",
    "            print(\"Len preprocessed:\", len(os.listdir(save_dir)))\n",
    "    else:\n",
    "        processor(root_data_dir, save_dir)\n",
    "        print(\"Data preprocessing complete\")\n",
    "        print(\"Len preprocessed:\", len(os.listdir(save_dir)))\n",
    "    end = time.time()\n",
    "    print(f\"Total time taken : {(end-start):.2f}s\")\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    ROOT_DATA_DIR = Path(\"/content/drive/MyDrive/research/driving_dataset\")\n",
    "    DATA_DIR = Path(\"/content/driving_dataset_preprocessed\")\n",
    "    ALT_DIR_PATH = Path(\"/content/drive/MyDrive/research/driving_dataset_preprocessed\")\n",
    "    EXP_DIR = Path(\"/content/drive/MyDrive/research/experiments\")\n",
    "    \n",
    "    if ALT_DIR_PATH.exists():\n",
    "        shutil.copytree(ALT_DIR_PATH, DATA_DIR)\n",
    "except:\n",
    "    ROOT_DATA_DIR = Path(\"/home/avishkar/Desktop/research/driving_dataset\")\n",
    "    DATA_DIR = Path(\"/home/avishkar/Desktop/research/driving_dataset_preprocessed\")\n",
    "    EXP_DIR = Path(\"/home/avishkar/Desktop/research/experiments\")\n",
    "    \n",
    "preprocess(ROOT_DATA_DIR, DATA_DIR, delete_existing=True)\n",
    "\n",
    "\n",
    "\n",
    "LABELS_PATH = DATA_DIR/\"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DATASET\"\"\"\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, labels_path, data_dir, transform=None):\n",
    "        with open(Path(labels_path), \"r\") as f:\n",
    "            self.labels = f.readlines()\n",
    "            f.close()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        img_path, label = self.labels[index].split()\n",
    "        label=float(label)\n",
    "        img = Image.open(self.data_dir/img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, label)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "dataset = DrivingDataset(labels_path=LABELS_PATH, data_dir=DATA_DIR, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(len(dataset)-train_size)\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "for i, (imgs, labels) in enumerate(train_loader):\n",
    "    img = imgs[0]\n",
    "    label = labels[0]\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "    plt.title(f\"Steering angle: {label.item()}\")\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MODEL\"\"\"\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet50SteeringPred(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ResNet50SteeringPred, self).__init__()\n",
    "        self.ResNet = models.resnet50(pretrained=True, progress=True) # Output dim = 1000\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features =1000, out_features = 256, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features = 256, out_features = 64, bias=True)\n",
    "        self.fc3 = nn.Linear(in_features = 64, out_features = 1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        image = self.ResNet(x)\n",
    "        # input size = (1,3,32,32)-(Batches, Channels, Height, Width)\n",
    "        # output size = (1, 1000)-(Batches, Feature)\n",
    "        image = F.relu(self.fc1(image))\n",
    "        # input size = (1,1000)-(batches, features)\n",
    "        # output size = (1,512)-(batches, features)\n",
    "        image = F.relu(self.fc2(image))\n",
    "        # input size = (1,512)-(batches, features)\n",
    "        # output size = (1,256)-(batches, features)\n",
    "        angle = self.fc3(image)\n",
    "        # input size = (1,256)-(batches, features)\n",
    "        # output size = (1,64)-(batches, features)\n",
    "        # angle = self.fc4(image)\n",
    "        # input size = (1,64)-(batches, features\n",
    "        # output size = (1,1)-(batches, features)\n",
    "        return angle\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTILS\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def save_checkpoint(state_dict, epoch, path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(\"Creating folder\")\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_details = {\n",
    "        \"epoch\":epoch,\n",
    "        \"state_dict\": state_dict,\n",
    "    }\n",
    "    torch.save(model_details, f\"{p}/vit_cifar10_{epoch}.pth\")\n",
    "    print(f\"model saved at path : {p}/vit_cifar10_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def load_pretrained(model, path, epoch):\n",
    "    model.load_state_dict(torch.load(f\"{path}/vit_cifar10_{epoch}.pth\")[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "def save_experiment(model, epoch, config, train_losses, test_losses, train_accuracies,test_accuracies, path):\n",
    "    exp_data = {\n",
    "        \"train_losses\":train_losses,\n",
    "        \"test_losses\":test_losses,\n",
    "        \"train_accuracies\":train_accuracies,\n",
    "        \"test_accuracies\":test_accuracies,\n",
    "        \"epoch\":epoch,\n",
    "    }\n",
    "    exp_name = config[\"exp_name\"]\n",
    "    config_file = path/f\"{exp_name}\"/\"config.json\"\n",
    "    metrics_file = path/f\"{exp_name}\"/\"metrics.json\"\n",
    "    files = [config_file , metrics_file]\n",
    "    for file in files:\n",
    "        if file.exists():\n",
    "            print(f\"{file} exists\")\n",
    "        else:\n",
    "            file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            file.touch()\n",
    "            print(f\"{file} created\")\n",
    "\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(exp_data, f, sort_keys=True, indent=4)\n",
    "\n",
    "    save_checkpoint(model.state_dict(), epoch, path/f\"{exp_name}\")\n",
    "\n",
    "def load_experiment(model ,exp_name, path):\n",
    "    with open(path/f\"{exp_name}\"/\"metrics.json\", 'r') as file:\n",
    "      data = json.load(file)\n",
    "    train_losses=data[\"train_losses\"]\n",
    "    test_losses=data[\"test_losses\"]\n",
    "    train_accuracies=data[\"train_accuracies\"]\n",
    "    test_accuracies=data[\"test_accuracies\"]\n",
    "    epoch=data[\"epoch\"]\n",
    "\n",
    "    model = load_pretrained(model, path/exp_name, epoch)\n",
    "\n",
    "    return model, train_losses, test_losses, train_accuracies,test_accuracies, epoch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "        \n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"exp_name\":\"vit_mnist_40_epoch\",\n",
    "        \"num_epoch\":40\n",
    "    }\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, device):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, train_loader, test_loader, num_epochs):\n",
    "        train_losses, test_losses, train_accuracies, test_accuracies = [], [] , [], []\n",
    "        start = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "            ep_start = time.time()\n",
    "            train_loss, train_accuracy = self.train_epoch(train_loader)\n",
    "            test_loss, test_accuracy = self.evaluate(test_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "            ep_end = time.time()\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Time : {(ep_end-ep_start):.2f}s\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"Train Accuracy : {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "            \n",
    "        save_experiment(self.model, num_epochs, config, train_losses, test_losses, train_accuracies,test_accuracies, EXP_DIR)\n",
    "        end = time.time()\n",
    "        print(f\"Total Training Time : {(end-start):.2f}s\")\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        correct = 0\n",
    "        running_train_loss = 0\n",
    "        for i, (imgs, labels) in enumerate(tqdm(train_loader, position=0, leave=True)):\n",
    "            imgs = imgs.float().to(self.device)\n",
    "            labels = labels.float().to(self.device)\n",
    "\n",
    "            predictions = self.model(imgs)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            running_train_loss += loss.item() * len(imgs)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        return train_loss, accuracy\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        running_test_loss = 0\n",
    "        for i, (imgs, labels) in enumerate(tqdm(test_loader, position=0, leave=True)):\n",
    "            imgs = imgs.to(self.device)\n",
    "            labels = labels.type(torch.uint8).to(self.device)\n",
    "\n",
    "            predictions = self.model(imgs)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            running_test_loss += loss.item() * len(imgs)\n",
    "\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "        test_loss = running_test_loss / len(test_loader.dataset)\n",
    "        return test_loss, accuracy\n",
    "            \n",
    "def main():\n",
    "    model = ResNet50SteeringPred(config)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    trainer = Trainer(model, criterion, optimizer, config[\"device\"])\n",
    "    trainer.train(train_loader, test_loader, config[\"num_epoch\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Visualize Losses\"\"\"\n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "model = ResNet50SteeringPred(config)\n",
    "_, train_losses, test_losses, train_accuracies, test_accuracies,_ = load_experiment(model, config[\"exp_name\"], EXP_DIR)\n",
    "# Create two subplots of train/test losses and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(train_losses, label=\"Train loss\")\n",
    "ax1.plot(test_losses, label=\"Test loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "ax2.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "ax2.plot(test_accuracies, label=\"Test accuracy\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "plt.savefig(\"metrics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
